#!/usr/bin/env python3
"""
ç»¼åˆç¼“å­˜æ›´æ–°è„šæœ¬ - åŒæ—¶æ›´æ–°ä¸¤ä¸ªæ•°æ®åº“
æ•°æ®åº“1: http://45.78.231.212:8001
æ•°æ®åº“2: http://10.252.176.14:8001
"""
import requests
import json
import os
from datetime import datetime
import argparse

# æ•°æ®åº“é…ç½®
DATABASES = {
    "db1": {
        "name": "æ•°æ®åº“1",
        "cache_file": "cache_db1.json",
        "api_url": "http://45.78.231.212:8001"
    },
    "db2": {
        "name": "æ•°æ®åº“2", 
        "cache_file": "cache_db2.json",
        "api_url": "http://10.252.176.14:8001"
    }
}

def load_cache(cache_file):
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"ç¼“å­˜æ–‡ä»¶ {cache_file} æŸå: {e}ï¼Œé‡æ–°åˆ›å»º")
    
    return {"total_records_at_last_run": 0, "results": []}

def save_cache(data, cache_file, db_name):
    with open(cache_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    print(f"âœ… {db_name}ç¼“å­˜å·²ä¿å­˜åˆ° {cache_file}")

def get_total_records(api_url):
    try:
        response = requests.get(f"{api_url}/stats", timeout=30)
        if response.status_code == 200:
            return response.json().get('total_records', 0)
    except Exception as e:
        print(f"è·å–æ€»æ•°å¤±è´¥ ({api_url}): {e}")
    return 0

def fetch_element(api_url, index):
    try:
        response = requests.get(f"{api_url}/elements/with-score/by-index/{index}", timeout=30)
        if response.status_code == 200:
            return response.json()
    except Exception as e:
        print(f"è·å–ç´¢å¼• {index} å¤±è´¥ ({api_url}): {e}")
    return None

def update_database(db_key):
    """æ›´æ–°å•ä¸ªæ•°æ®åº“"""
    config = DATABASES[db_key]
    db_name = config["name"]
    cache_file = config["cache_file"]
    api_url = config["api_url"]
    
    print(f"\nğŸ”„ å¼€å§‹æ›´æ–°{db_name}...")
    
    cache = load_cache(cache_file)
    current_total = get_total_records(api_url)
    
    if current_total == 0:
        print(f"âŒ æ— æ³•è¿æ¥{db_name} API: {api_url}")
        return False
    
    last_total = cache.get("total_records_at_last_run", 0)
    results = cache.get("results", [])
    
    print(f"{db_name} APIæ€»è®°å½•: {current_total}, ç¼“å­˜è®°å½•: {last_total}")
    
    if current_total <= last_total:
        print(f"ğŸ“ {db_name}æ²¡æœ‰æ–°æ•°æ®")
        return True
    
    # è·å–æ–°æ•°æ®
    new_count = 0
    for i in range(last_total + 1, current_total + 1):
        print(f"è·å–{db_name}ç´¢å¼• {i}...")
        data = fetch_element(api_url, i)
        
        if data and 'result' in data:
            entry = {
                "index": i,
                "name": data.get('name', f'model_{i}'),
                "parent": data.get('parent'),
                "test": data['result'].get('test', ''),
                "train": data['result'].get('train', ''),
                "score": data.get('score'),
                "timestamp": datetime.now().isoformat()
            }
            results.append(entry)
            new_count += 1
            print(f"âœ… {db_name}: {entry['name']}")
        else:
            print(f"âš ï¸ {db_name}ç´¢å¼• {i} æ•°æ®æ— æ•ˆ")
    
    # ä¿å­˜ç¼“å­˜
    cache.update({
        "total_records_at_last_run": current_total,
        "results": results,
        "last_update": datetime.now().isoformat()
    })
    
    save_cache(cache, cache_file, db_name)
    print(f"ğŸ‰ {db_name}æ–°å¢ {new_count} æ¡è®°å½•ï¼Œæ€»è®¡ {len(results)} æ¡")
    return True

def main():
    parser = argparse.ArgumentParser(description='æ›´æ–°AIæ¨¡å‹æ•°æ®åº“ç¼“å­˜')
    parser.add_argument('--db', choices=['db1', 'db2', 'all'], default='all',
                        help='é€‰æ‹©è¦æ›´æ–°çš„æ•°æ®åº“ (db1, db2, or all)')
    parser.add_argument('--force', action='store_true',
                        help='å¼ºåˆ¶é‡æ–°è·å–æ‰€æœ‰æ•°æ®')
    
    args = parser.parse_args()
    
    if args.force:
        print("âš ï¸ å¼ºåˆ¶æ¨¡å¼ï¼šå°†é‡æ–°è·å–æ‰€æœ‰æ•°æ®")
        for db_key in DATABASES.keys():
            cache_file = DATABASES[db_key]["cache_file"]
            if os.path.exists(cache_file):
                os.remove(cache_file)
                print(f"ğŸ—‘ï¸ å·²åˆ é™¤ {cache_file}")
    
    # æ‰§è¡Œæ›´æ–°
    success_count = 0
    total_count = 0
    
    if args.db == 'all':
        databases_to_update = list(DATABASES.keys())
    else:
        databases_to_update = [args.db]
    
    for db_key in databases_to_update:
        total_count += 1
        if update_database(db_key):
            success_count += 1
    
    # æ€»ç»“
    print(f"\n{'='*50}")
    print(f"ğŸ“Š æ›´æ–°å®Œæˆ: {success_count}/{total_count} ä¸ªæ•°æ®åº“æˆåŠŸæ›´æ–°")
    
    if success_count == total_count:
        print("ğŸ‰ æ‰€æœ‰æ•°æ®åº“æ›´æ–°æˆåŠŸï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æ•°æ®åº“æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIçŠ¶æ€")
    
    # æ˜¾ç¤ºæ–‡ä»¶çŠ¶æ€
    print(f"\nğŸ“ ç”Ÿæˆçš„ç¼“å­˜æ–‡ä»¶:")
    for db_key in databases_to_update:
        cache_file = DATABASES[db_key]["cache_file"]
        if os.path.exists(cache_file):
            size = os.path.getsize(cache_file)
            print(f"  - {cache_file}: {size:,} bytes")
        else:
            print(f"  - {cache_file}: æ–‡ä»¶ä¸å­˜åœ¨")

if __name__ == "__main__":
    main()